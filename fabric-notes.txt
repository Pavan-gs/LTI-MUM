- Microsoft **Fabric** is an enterprise-ready, **end-to-end analytics platform**. 

- It unifies data movement, data processing, ingestion, transformation, real-time event routing, and report building. **(ADF + Synpase + Data Science + PowerBI + OneLake)** 

- It supports these capabilities with integrated services like Data Engineering, Data Factory, Data Science, Real-Time Intelligence, Data Warehouse, Lake House, and Databases. 

- It integrates separate components into a **cohesive** stack. - It centralizes data storage with **OneLake** and embeds **AI** capabilities, eliminating the need for manual integration. 

- With Fabric, you can efficiently transform **raw data** into **actionable insights** - Go through website https://www.microsoft.com/en-us/microsoft-fabric


## **Microsoft Fabric Architecture**
- Unification with **SaaS** foundation
- Microsoft Fabric is built on a Software as a Service (SaaS) platform.
- It unifies new and existing components from Power BI, Azure Synapse Analytics, Azure Data Factory, and more into a single environment.

  
## OneLake
- OneLake, the OneDrive for data
- OneLake is a single, unified, logical data lake for your whole organization. Like OneDrive, OneLake comes automatically with every **Microsoft Fabric tenant** and is designed to be the **single place** for all your analytics data
- OneLake is built on top of Azure Data Lake Storage (ADLS) Gen2 and can support any type of file, structured or unstructured
- Refer [msft help](https://learn.microsoft.com/en-us/fabric/onelake/onelake-overview)
- [Download and Install OneLake Client](https://www.microsoft.com/en-us/download/details.aspx?id=105222)

## **Key Features and Capabilities**
- **OneLake**: A single storage layer for all data within Microsoft Fabric, eliminating data silos.
- **Lakehouse Architecture**: Combines the benefits of data lakes and data warehouses, allowing structured and unstructured data management.
- **Integrated AI and Analytics**: Built-in machine learning and analytics capabilities for data processing and insights generation.
- **Unified Security and Governance**: Provides role-based access controls, data compliance, and security enforcement across all data assets.

## **Fabric vs. Other Data Platforms**
- **Azure Synapse vs. Fabric**:
  - Synapse is more focused on data warehousing and big data analytics, while Fabric provides an **all-in-one** data solution.
- **Databricks vs. Fabric**:
  - Databricks is centered around big data and AI workloads, whereas Fabric integrates **BI, ML, AI and real-time analytics**.
- **Snowflake vs. Fabric**:
  - Snowflake provides a cloud-based data warehouse, while Fabric offers a **broader ecosystem** with integrated services.
- Fabricâ€™s advantage lies in **end-to-end integration**, making it suitable for enterprises looking for a complete data solution.

## **Refer**
- [Refer microsoft-fabric-overview](https://learn.microsoft.com/en-us/fabric/fundamentals/microsoft-fabric-overview)

## Exercise 1: Get MSFT Login
1. Get any one personal mail id (Recommended Outlook mailid) https://signup.live.com/?lic=1


2. Follow this link https://learn.microsoft.com/en-us/power-bi/enterprise/service-admin-signing-up-for-power-bi-with-a-new-office-365-trial
## Exercise 2: Create Workspace

1. Open your browser and navigate to https://app.fabric.microsoft.com.
2. Sign in with your Microsoft account that has Fabric access.
3. On the left navigation pane, click on **Workspaces**.
4. Click on workspaces
5. Enter a Workspace name (e.g.,demo_Workspace**)
6. Click **Apply**


7. Your new workspace is now available under the Workspaces section


===============================================================================================================================================

# Module 03: SQL Analytics Endpoint

## Microsoft Fabric SQL Analytics Endpoint
- The SQL Analytics Endpoint in Microsoft Fabric is a key component that allows users to query and analyze data stored in OneLake using SQL-based tools and services.
- It provides a **serverless SQL** experience, enabling seamless integration with **Power BI, Azure Synapse, and other analytical tools**.

## Sample Data Setup

1. Create a new Lakehouse or open an existing one.  
2. Upload the `emp.csv` and `dept.csv` files into the **Lakehouse data** folder.  
3. For each file, right-click and choose **Create Table**, assigning it to the `dbo` schema.
4. Click on SQL analytics endpoint
5. Click on **New SQL Query**

## 1. **Basic Queries**
### **1.1 Select All Data**
```sql
SELECT * FROM emp;
SELECT * FROM dept;
```
### **1.2 Selecting Specific Columns**

1. [what-is-column-pruning]
```sql
SELECT empno, ename, job, sal FROM emp;
SELECT deptno, dname, loc FROM dept;
```

---

## 2. **Joins - Combining `emp` and `dept` Tables**
### **2.1 INNER JOIN - Employees with Departments**
```sql
SELECT e.empno, e.ename, e.job, e.sal, d.dname, d.loc
FROM emp e
INNER JOIN dept d ON e.deptno = d.deptno;
```

### **2.2 LEFT JOIN - All Employees, Even Without Departments**
```sql
SELECT e.empno, e.ename, e.job, e.sal, d.dname, d.loc
FROM emp e
LEFT JOIN dept d ON e.deptno = d.deptno;
```

### **2.3 Right JOIN - All Departments, Even Without Employees**
```sql
SELECT e.empno, e.ename, e.job, e.sal, d.dname, d.loc
FROM emp e
RIGHT JOIN dept d ON e.deptno = d.deptno;
```

### **2.4 FULL OUTER JOIN - Show All Employees and Departments**
```sql
SELECT e.empno, e.ename, e.job, e.sal, d.dname, d.loc
FROM emp e
FULL OUTER JOIN dept d ON e.deptno = d.deptno;
```

---

## 3. **Aggregations & Grouping**
### **3.1 Count Employees per Department**
```sql
SELECT d.dname, COUNT(e.empno) AS employee_count
FROM dept d
LEFT JOIN emp e ON d.deptno = e.deptno
GROUP BY d.dname;
```

### **3.2 Average Salary per Department**
```sql
SELECT d.dname, AVG(e.sal) AS avg_salary
FROM dept d
LEFT JOIN emp e ON d.deptno = e.deptno
GROUP BY d.dname;
```

### **3.3 Employees with Salary Above Department Average**
```sql
SELECT e.ename, e.sal, d.dname
FROM emp e
JOIN dept d ON e.deptno = d.deptno
WHERE e.sal > (
    SELECT AVG(sal) FROM emp WHERE deptno = e.deptno
);
```

### **3.4 Understand all**
```

SELECT 
    d.dname,
    
    COUNT(*) AS total_rows,                                -- Total rows (including NULLs in LEFT JOIN)
    COUNT(e.empno) AS employee_count,                      -- Total employees (excluding NULLs from unmatched departments)
    
    SUM(e.sal) AS total_salary,                            -- Total salary in the department
    AVG(e.sal) AS avg_salary,                              -- Average salary
    MIN(e.sal) AS min_salary,                              -- Minimum salary
    MAX(e.sal) AS max_salary,                              -- Maximum salary    


    COUNT(DISTINCT e.job) AS distinct_jobs,                -- Number of distinct job roles
    COUNT(DISTINCT e.sal) AS distinct_salaries           -- Number of distinct salaries


FROM dept d
LEFT JOIN emp e ON d.deptno = e.deptno
GROUP BY d.dname;
```
---

## 4. **Window Functions**
### **4.1 Rank Employees by Salary per Department**
```sql
SELECT 
    e.empno,
    e.ename,
    --e.job,
    --e.mgr,
    --e.hiredate,   
    --e.comm,
    e.deptno,
    d.dname,
     e.sal,

    -- -- RANKING FUNCTIONS
    RANK() OVER (ORDER BY e.sal DESC) AS salary_rank
    -- DENSE_RANK() OVER (ORDER BY e.sal DESC) AS salary_dense_rank,
    -- ROW_NUMBER() OVER (ORDER BY e.sal DESC) AS salary_row_number,
    -- NTILE(4) OVER (ORDER BY e.sal DESC) AS salary_quartile,

    -- -- AGGREGATE WINDOW FUNCTIONS
    -- SUM(e.sal) OVER (PARTITION BY e.deptno) AS dept_total_salary,
    -- AVG(e.sal) OVER (PARTITION BY e.deptno) AS dept_avg_salary,
    -- MIN(e.sal) OVER (PARTITION BY e.deptno) AS dept_min_salary,
    -- MAX(e.sal) OVER (PARTITION BY e.deptno) AS dept_max_salary,
    -- COUNT(*) OVER (PARTITION BY e.deptno) AS dept_emp_count,

    -- -- RUNNING TOTALS
    -- SUM(e.sal) OVER (ORDER BY e.sal ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS running_total_salary,
    -- AVG(e.sal) OVER (ORDER BY e.sal ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS running_avg_salary,

    -- -- LAG/LEAD
    -- LAG(e.sal, 1) OVER (ORDER BY e.sal DESC) AS prev_salary,
    -- LEAD(e.sal, 1) OVER (ORDER BY e.sal DESC) AS next_salary,

    -- -- FIRST_VALUE, LAST_VALUE
    -- FIRST_VALUE(e.sal) OVER (PARTITION BY e.deptno ORDER BY e.sal DESC) AS dept_highest_salary,
    -- LAST_VALUE(e.sal) OVER (PARTITION BY e.deptno ORDER BY e.sal DESC 
    --     ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS dept_lowest_salary



FROM emp e
JOIN dept d ON e.deptno = d.deptno
order by sal desc;

```

### **4.2 Running Total of Salaries**
```sql
SELECT e.ename, e.sal,
       SUM(e.sal) OVER (ORDER BY e.sal) AS running_total
FROM emp e;
```

---

## 5. **Common Table Expressions (CTEs)**
### **5.1 Finding Highest Paid Employee per Department**
```sql
WITH RankedSalaries AS (
    SELECT e.ename, e.sal, e.deptno,
           RANK() OVER (PARTITION BY e.deptno ORDER BY e.sal DESC) AS rnk
    FROM emp e
)
SELECT ename, sal, deptno FROM RankedSalaries WHERE rnk = 1;
```
### **5.2 Department-Level Salary Summary + Rank Each Employee Within Their Department**
```
WITH DeptStats AS (
    SELECT 
        deptno,
        SUM(sal) AS dept_total_salary,
        AVG(sal) AS dept_avg_salary
    FROM emp
    GROUP BY deptno
),
EmpRanked AS (
    SELECT 
        e.empno,
        e.ename,
        e.sal,
        e.deptno,
        d.dname,
        RANK() OVER (PARTITION BY e.deptno ORDER BY e.sal DESC) AS salary_rank
    FROM emp e
    JOIN dept d ON e.deptno = d.deptno
)
SELECT 
    er.empno,
    er.ename,
    er.sal,
    er.dname,
    er.salary_rank,
    ds.dept_total_salary,
    ds.dept_avg_salary,
    ROUND(er.sal - ds.dept_avg_salary, 2) AS diff_from_avg,
    CASE
        WHEN er.sal > ds.dept_avg_salary THEN 'Above Avg'
        WHEN er.sal < ds.dept_avg_salary THEN 'Below Avg'
        ELSE 'At Avg'
    END AS salary_position
FROM EmpRanked er
JOIN DeptStats ds ON er.deptno = ds.deptno
ORDER BY er.dname, er.salary_rank;

```
---

## 6. Views

# **6.1 Creating a View for Employees with Department Names**
```sql
CREATE VIEW vw_emp_details AS
SELECT e.empno, e.ename, e.job, e.sal, d.dname, d.loc
FROM emp e
JOIN dept d ON e.deptno = d.deptno;
```

### **6.2 Querying the View**
```sql
SELECT * FROM vw_emp_details;
```

---


=========================================================================

# Microsoft Fabric SQL Analytics Endpoint - Visual Query Examples

## Example 1: Visual Query to Analyze Employee Salary Distribution
### **Step 1: Open the Visual Query Editor**
1. Go to **Microsoft Fabric** and navigate to your **SQL Analytics Endpoint**.
2. Select your database and click on **Visual Query**.

### **Step 2: Add Tables**
1. Drag and drop the `emp` table onto the canvas.
2. Drag and drop the `dept` table onto the canvas.

### **Step 3: Create a Join**
1. Connect `emp.deptno` with `dept.deptno` to create an **INNER JOIN**.
2. Select **Columns to Include**:
   - `emp.ename`
   - `emp.job`
   - `emp.sal`
   - `dept.dname`

### **Step 4: Add Aggregations**
1. Click on **Aggregations**.
2. Choose **Average Salary (AVG)** for `sal` grouped by `dept.dname`.
3. Click **Run** to execute the query.

## Example 2: Visual Query to Filter High-Earning Employees
### **Step 1: Open the Visual Query Editor**
1. Navigate to **Visual Query** in your **SQL Analytics Endpoint**.
2. Drag the `emp` table to the canvas.

### **Step 2: Apply Filters**
1. Click on `sal` and add a filter **Greater than 5000**.
2. Select columns to display:
   - `emp.ename`
   - `emp.job`
   - `emp.sal`

### **Step 3: Sort Results**
1. Sort `sal` in **Descending Order**.
2. Click **Run**.

### **Generated SQL Query:**
```sql
SELECT ename, job, sal 
FROM emp 
WHERE sal > 5000 
ORDER BY sal DESC;
```

# Module 03_3: SQL Analytics Endpoint - Report

## Step 1: Create Semantic Model
1. Click on Reporting Tab
2. Click on New Semantic Model
3. Name i ias **emp-dept** and select **emp** and **dept** tables > click on **Confirm**
4. Go back to workspace open the emp-dept semantic model
5. Click on **Open Data Model**
6. Change **Viewing** model to **Editing** Mode
7. Drag and drop deptno from emp table to deptno of dept table(If any refresh do same again)

## Step 2: Create Semantic Model

1. Click on **File** Menu > Click on **Create New Report**
2. select dname and sal columns > clik on pie chart similarly develop new reports (POWERBI Resource can work better in this area)
3. Click on **File** Menu > Click on **Save** > Name it as **dname wise sal** > click on **save**








   